
sys:
    name: MCP 客户端
api:
    llm_api_uri: https://api.deepseek.com/v1
    llm_api_key: your_api_key , like sk-****
    llm_model_name: your_llm_model_name, like deepseek-chat
    # if you have no proxy to request the llm api , the key 'proxy' following can be deleted
    proxy: {"http": "http://proxy.your.company.domain:8080", "https": "http://proxy.your.company.domain:8080"}

mcp:
   # mcp server list
    server_list: ["https://localhost:19001/mcp"]
