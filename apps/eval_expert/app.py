#!/usr/bin/env python3
# -*- coding: utf-8 -*-
# Copyright (c) [2025] [liuyngchng@hotmail.com] - All rights reserved.

"""
é¡¹ç›®è¯„å®¡æ•°å­—ä¸“å®¶
pip install gunicorn flask concurrent-log-handler requests \
 pycryptodome
"""
import asyncio
import json
import logging.config
import os
import time
import threading
from datetime import datetime

from werkzeug.middleware.proxy_fix import ProxyFix
from flask import Flask, request, redirect, abort, url_for, send_from_directory, render_template, Response
from apps.eval_expert.agent import EvalExpertAgent
from common.docx_util import get_md_file_content
from common.my_enums import AppType
from common.sys_init import init_yml_cfg
from common.bp_auth import auth_bp, auth_info, get_client_ip, SESSION_TIMEOUT
from common.bp_vdb import vdb_bp, clean_expired_vdb_file_task, process_vdb_file_task
from common.cm_utils import get_console_arg1
from common import statistic_util, my_enums

logging.config.fileConfig('logging.conf', encoding="utf-8")
logger = logging.getLogger(__name__)

my_cfg = init_yml_cfg()
os.system(
    "unset https_proxy ftp_proxy NO_PROXY FTP_PROXY HTTPS_PROXY HTTP_PROXY http_proxy ALL_PROXY all_proxy no_proxy"
)

# å…¨å±€å˜é‡ï¼Œç”¨äºå­˜å‚¨åå°ä»»åŠ¡çŠ¶æ€
background_tasks_started = False
background_tasks_lock = threading.Lock()

UPLOAD_FOLDER = 'upload_doc'

def create_app():
    """åº”ç”¨å·¥å‚å‡½æ•°"""
    app = Flask(__name__, static_folder=None)
    app.wsgi_app = ProxyFix(app.wsgi_app, x_proto=1, x_host=1)
    app.config['JSON_AS_ASCII'] = False
    app.config['MY_CFG'] = my_cfg

    # æ³¨å†Œè“å›¾
    app.register_blueprint(auth_bp)
    app.register_blueprint(vdb_bp)

    # æ³¨å†Œè·¯ç”±
    register_routes(app)

    # åœ¨åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–åå°ä»»åŠ¡ï¼ˆä½¿ç”¨åº”ç”¨ä¸Šä¸‹æ–‡ï¼‰
    # with app.app_context():
    #     start_background_tasks_once()

    return app


def start_background_tasks_once():
    """ç¡®ä¿åå°ä»»åŠ¡åªå¯åŠ¨ä¸€æ¬¡"""
    global background_tasks_started
    with background_tasks_lock:
        if not background_tasks_started:
            logger.info("start_init_bg_task...")
            start_background_tasks()
            background_tasks_started = True


def register_routes(app):
    """æ³¨å†Œæ‰€æœ‰è·¯ç”±"""

    @app.route('/static/<path:file_name>')
    def get_static_file(file_name):
        static_dirs = [
            os.path.join(os.path.dirname(__file__), '../../common/static'),
            os.path.join(os.path.dirname(__file__), 'static'),
        ]

        for static_dir in static_dirs:
            if os.path.exists(os.path.join(static_dir, file_name)):
                # logger.debug(f"get_static_file, {static_dir}, {file_name}")
                return send_from_directory(static_dir, file_name)
        logger.error(f"no_file_found_error, {file_name}")
        abort(404)

    @app.route('/webfonts/<path:file_name>')
    def get_webfonts_file(file_name):
        font_file_name = f"webfonts/{file_name}"
        return get_static_file(font_file_name)

    @app.route('/')
    def app_home():
        logger.info("redirect_auth_login_index")
        return redirect(url_for('auth.login_index', app_source=AppType.EVAL_EXPERT.name.lower()))


    @app.route('/chat/statistic/index', methods=['GET'])
    def get_statistic_report_index():
        """
        è·å–ç³»ç»Ÿè¿è¥çš„é¡µé¢
        """
        logger.info(f"get_statistic_report_index, {request.args}")
        uid = request.args.get('uid')
        session_key = f"{uid}_{get_client_ip()}"
        if (not auth_info.get(session_key, None)
                or time.time() - auth_info.get(session_key) > SESSION_TIMEOUT):
            warning_info = "ç”¨æˆ·ä¼šè¯ä¿¡æ¯å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•"
            logger.warning(f"{uid}, {warning_info}")
            return redirect(url_for(
                'auth.login_index',
                app_source=AppType.EVAL_EXPERT.name.lower(),
                warning_info=warning_info
            ))
        app_source = request.args.get('app_source')
        warning_info = request.args.get('warning_info', "")
        sys_name = my_enums.AppType.get_app_type(app_source)
        ctx = {
            "uid": uid,
            "sys_name": sys_name,
            "app_source": app_source,
            "warning_info": warning_info,
        }
        dt_idx = "statistics.html"
        logger.info(f"{uid}, return_statistics_page {dt_idx}")
        return render_template(dt_idx, **ctx)


    @app.route('/chat/statistic/report', methods=['POST'])
    def get_statistic_report():
        """
        ç»Ÿè®¡ç”¨æˆ·çš„ç³»ç»Ÿä½¿ç”¨æ•°æ®
        """
        data = request.json
        uid = int(data.get('uid'))
        logger.info(f"{uid}, get_statistic_report, {data}")
        session_key = f"{uid}_{get_client_ip()}"
        if (not auth_info.get(session_key, None)
                or time.time() - auth_info.get(session_key) > SESSION_TIMEOUT):
            warning_info = "ç”¨æˆ·ä¼šè¯ä¿¡æ¯å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•"
            logger.warning(f"{uid}, {warning_info}")
            return redirect(url_for(
                'auth.login_index',
                app_source=AppType.EVAL_EXPERT.name.lower(),
                warning_info=warning_info
            ))
        statistics_list = statistic_util.get_statistics_list()
        return json.dumps(statistics_list, ensure_ascii=False), 200

    @app.route('/chat/stream', methods=['POST'])
    def chat_stream():
        """æ–°çš„æµå¼èŠå¤©æ¥å£"""
        logger.info(f"chat_stream_request {request.form}")
        msg = request.form.get('msg', "").strip()
        uid = request.form.get('uid')
        file_infos = request.form.get('file_infos')

        # éªŒè¯é€»è¾‘
        if not file_infos:
            return json.dumps({"error": "ç¼ºå°‘è¯„å®¡æ–‡ä»¶ä¿¡æ¯"}, ensure_ascii=False), 400

        if not uid:
            return json.dumps({"error": "ç¼ºå°‘ç”¨æˆ·èº«ä»½ä¿¡æ¯"}, ensure_ascii=False), 400

        session_key = f"{uid}_{get_client_ip()}"
        if (not auth_info.get(session_key, None) or
                time.time() - auth_info.get(session_key) > SESSION_TIMEOUT):
            return json.dumps({"error": "ç”¨æˆ·ç™»å½•ä¿¡æ¯å·²å¤±æ•ˆ"}, ensure_ascii=False), 401

        logger.info(f"rcv_msg, {msg}, uid {uid}")
        auth_info[session_key] = time.time()

        def generate():
            try:
                # åˆå§‹åŒ–agent
                eval_expert = EvalExpertAgent(my_cfg)

                # åœ¨ç”Ÿæˆå™¨å†…éƒ¨è¿è¡Œå¼‚æ­¥ä»£ç 
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)

                # å¤„ç†æ–‡ä»¶åˆ†ç±»
                file_info_list = json.loads(file_infos)
                categorize_files = eval_expert.categorize_files(file_info_list)
                logger.info(f"categorize_files, {categorize_files}")

                # å¤„ç†æ–‡ä»¶å†…å®¹
                review_criteria_file = eval_expert.get_file_path_msg(categorize_files, "review_criteria")
                review_criteria = ''
                for file in review_criteria_file:
                    review_criteria += get_md_file_content(file['file_path'])
                project_material_file = eval_expert.get_file_path_msg(categorize_files, "project_materials")

                stream_input = {
                    "today": datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥"),
                    "domain": "ç‡ƒæ°”è¡Œä¸š",
                    "review_criteria": review_criteria,
                    "project_material_file": project_material_file,
                    "msg": msg
                }

                # ä½¿ç”¨çœŸæ­£çš„æµå¼å¤„ç†
                collected_chunks = []

                def stream_callback(chunk):
                    # ç«‹å³å‘é€åˆ°å®¢æˆ·ç«¯
                    data = json.dumps({'content': chunk}, ensure_ascii=False)
                    yield f"data: {data}\n\n"
                    collected_chunks.append(chunk)
                    return ""  # ç¡®ä¿è¿”å›å­—ç¬¦ä¸²

                # æ‰§è¡ŒçœŸæ­£çš„æµå¼å¤„ç† - åŒæ­¥æ–¹å¼è°ƒç”¨å¼‚æ­¥å‡½æ•°
                full_response = loop.run_until_complete(
                    real_process_with_streaming(eval_expert, stream_input, stream_callback)
                )
                loop.close()

                # å‘é€ç»“æŸæ ‡è®°
                yield "data: [DONE]\n\n"

                logger.info(f"æµå¼å¤„ç†å®Œæˆï¼Œæ€»å“åº”é•¿åº¦: {len(full_response)}")

            except Exception as e:
                logger.error(f"æµå¼å¤„ç†é”™è¯¯: {str(e)}")
                error_msg = json.dumps({'content': f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"}, ensure_ascii=False)
                yield f"data: {error_msg}\n\n"
                yield "data: [DONE]\n\n"

        return Response(generate(), mimetype='text/event-stream')

    async def real_process_with_streaming(eval_expert, stream_input, stream_callback):
        """çœŸæ­£çš„æµå¼å¤„ç†å®ç°"""
        try:
            if not eval_expert.tools:
                await eval_expert.initialize_tools()

            # æ„å»ºæç¤ºè¯
            prompt = eval_expert.build_prompt(stream_input)

            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            stream_callback("ğŸš€ å¼€å§‹å¤„ç†æ‚¨çš„è¯·æ±‚...\n\n")

            # è°ƒç”¨LLM APIï¼ˆçœŸæ­£çš„æµå¼ï¼‰
            response = await eval_expert.real_call_llm_api_stream(prompt, stream_callback)

            # æ£€æŸ¥å“åº”ä¸­æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
            tool_calls = eval_expert.extract_tool_calls_from_response(response)

            if tool_calls:
                stream_callback(f"\nğŸ”§ æ£€æµ‹åˆ° {len(tool_calls)} ä¸ªå·¥å…·è°ƒç”¨ï¼Œå¼€å§‹æ‰§è¡Œ...\n\n")
                logger.info(f"æ£€æµ‹åˆ°å·¥å…·è°ƒç”¨: {len(tool_calls)} ä¸ª")
                final_response = await eval_expert.real_handle_tool_calls_stream(tool_calls, stream_input,
                                                                                 stream_callback)
                return final_response
            else:
                logger.info("æœªæ£€æµ‹åˆ°å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›å“åº”å†…å®¹")
                return response

        except Exception as e:
            error_msg = f"âŒ å¤„ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
            logger.error(f"å·¥å…·å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
            stream_callback(error_msg)
            return error_msg



    @app.route('/upload', methods=['POST'])
    def upload_file():
        """
        å•ä¸ªæ–‡ä»¶ä¸Šä¼ 
        """
        logger.info(f"upload_file, {request}")
        if 'file' not in request.files:
            return json.dumps({"error": "æœªæ‰¾åˆ°ä¸Šä¼ çš„æ–‡ä»¶ä¿¡æ¯"}, ensure_ascii=False), 400
        file = request.files['file']
        uid = int(request.form.get('uid'))
        logger.info(f"{uid}, upload_file")
        session_key = f"{uid}_{get_client_ip()}"
        if (not auth_info.get(session_key, None)
                or time.time() - auth_info.get(session_key) > SESSION_TIMEOUT):
            warning_info = "ç”¨æˆ·ä¼šè¯ä¿¡æ¯å·²å¤±æ•ˆï¼Œè¯·é‡æ–°ç™»å½•"
            logger.warning(f"{uid}, {warning_info}")
            return json.dumps({"error": f"{warning_info}"}, ensure_ascii=False), 400
        if file.filename == '':
            return json.dumps({"error": "ä¸Šä¼ æ–‡ä»¶çš„æ–‡ä»¶åä¸ºç©º"}, ensure_ascii=False), 400

        # ç”Ÿæˆä»»åŠ¡IDï¼Œ ä½¿ç”¨æ¯«ç§’æ•°
        file_id = int(time.time() * 1000)
        file_name = f"{file_id}_{file.filename}"
        save_path = os.path.join(UPLOAD_FOLDER, file_name)
        file.save(save_path)
        logger.info(f"{uid}, upload_file_saved_as {file_name}, {file_id}")
        info = {
            "file_id": file_id,
            "file_name": file_name,
        }
        logger.info(f"{uid}, file_uploaded, {info}")
        return json.dumps(info, ensure_ascii=False), 200




def start_background_tasks():
    """å¯åŠ¨åå°ä»»åŠ¡çº¿ç¨‹"""
    if my_cfg['sys'].get('debug_mode', False):
        logger.warning("system_in_debug_mode_background_task_exit")
        return

    def _start_tasks():
        # ç­‰å¾…åº”ç”¨å®Œå…¨å¯åŠ¨
        time.sleep(2)
        logger.info("Starting background tasks...")

        # å¯åŠ¨VDBæ¸…ç†ä»»åŠ¡
        vdb_clean_thread = threading.Thread(target=clean_expired_vdb_file_task, daemon=True, name="vdb_clean_task")
        vdb_clean_thread.start()

        # å¯åŠ¨VDBå¤„ç†ä»»åŠ¡
        vdb_process_thread = threading.Thread(target=process_vdb_file_task, daemon=True, name="vdb_process_task")
        vdb_process_thread.start()

        logger.info("all_bg_tasks_started")

    # åœ¨æ–°çº¿ç¨‹ä¸­å¯åŠ¨åå°ä»»åŠ¡ï¼Œé¿å…é˜»å¡ä¸»çº¿ç¨‹
    threading.Thread(target=_start_tasks, daemon=True).start()


# åˆ›å»ºåº”ç”¨å®ä¾‹
app = create_app()

# å½“ç›´æ¥è¿è¡Œè„šæœ¬æ—¶ï¼Œå¯åŠ¨å¼€å‘æœåŠ¡å™¨
if __name__ == '__main__':
    """
    just for test, not for a production environment.
    """
    logger.info(f"my_cfg {my_cfg.get('db')},\n{my_cfg.get('api')}")
    app.config['ENV'] = 'dev'
    port = get_console_arg1()
    logger.info(f"listening_port {port}")
    app.run(host='0.0.0.0', port=port)